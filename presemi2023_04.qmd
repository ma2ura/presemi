# Rによるデータ操作

第5回講義の**到達目標**は、

- 様々なデータをRで読み込むことができる。
- 読み込んだデータを確認できる。
- 基本的なデータ操作ができる。
- 整然データの構造を理解し、データを必要な形に成形できる。
- 複数のデータを結合できる。
- 作成したデータを保存できる。

第5回講義の**到達度検証のための課題**は、以下の通りです。

1. CSVファイル、Excelファイルを読み込んで、中身を確認する。
2. 必要なデータの抽出、変数の追加、変数の選択を行い、分析に適した形に持っていける。(`filter()`、`mutate()`,`select()`, `arrange()`, `pivot_longer()`, `pivot_wider()`)
3. データ結合の種類を理解し、複数のデータを結合して、1つのデータフレームを作成する。(`bind_rows()`, `bind_cols()`, `left_join()`, `right_join()`, `inner_join()`, `full_join()`)

```{r echo = FALSE}
library(tidyverse)
library(ggthemes)
```

この章では、Rを用いたデータ操作の基本的な方法を学びます。
この章は何度も読み返し、繰り返し練習してください。
ここでは、なぜRを使うと便利なのかを分かってもらうために、Excelの操作と比較する形で、Rのデータ操作の基本を学びます。

## データの読み込み

### CSVファイルの読み込み

多くのプログラミング言語で、読み込むデータとして最も多いのが、CSV形式のファイルです。ファイルの拡張子は`.csv`です。
CSVとは、Comma Separated Valuesの略で、カンマで区切られたデータのことです。
次のような形をしています。

```
企業ID,決算年月,売上高
13,2020/03,1000
13,2021/03,1200
13,2022/03,1500
24,2020/03,2000
24,2021/03,2200
24,2022/03,2500
33,2020/03,3000
33,2021/03,3200
33,2022/03,3500
```
このように、値とコンマ`,`のみで構成されたファイルのため、余計な情報が入っておらず、またファイルサイズも小さく、加工が簡単なので、データのやり取りによく使われます。

さっそくファイルを読み込んでみましょう。
ここでは、松浦のウェブサイトにあるデータ`keshohin_2023.csv`を読み込んでみます。
Rの場合は、`read.csv`という関数を使って、URLを直接指定して読み込むことができます。読み込んだデータを`df`という変数に代入しています。

Excelの場合は、インターネット上のデータを直接取り込むことは難しいので、いったんパソコンの中に保存してから、ファイルを開くとします。

:::{.callout-important}
## Rの場合

`R`でcsvファイルを読み込む最もシンプルな方法は、基本関数`read.csv()`を用いて、ファイル名やファイルを参照するURLを直接指定することです。
```{r}
df <- read.csv("https://so-ichi.com/kesho_2023.csv")
```
:::

::: {.callout-tip}
## MS Excelの場合

1. URL`https://so-ichi.com/kesho_2023.csv`をブラウザに入力してファイルをダウンロードし、任意の場所に保存
2. 「ファイル」から「開く...」をクリックして、保存したCSVファイルを選択し「開く」をクリック
:::

### Excelファイルの読み込み

MS Excelのファイルは拡張子が`.xlsx`、古いMS Excelだと`.xls`です。
RでExcelファイルを読み込むときは、`read_excel`という関数を使います。
Excelファイルを用意するのが面倒なので、ここではこうやれば読み込めるよ、というコードだけ説明します。ファイル名は`hoge.xlsx`とします。

:::{.callout-important}
## Rの場合

`R`でMS Excelのファイルを読み込むには、`readxl`パッケージの`read_excel()`関数を用います。

```{r}
#| eval: false
dfx <- readxl::read_excel("hoge.xlsx")
```
:::

::: {.callout-tip}
## MS Excelの場合

1. 「ファイル」から「開く...」をクリックし、保存してあるExcelファイルを選択し「開く」をクリック
:::

MS Excelの問題点は、目的のデータがどのExcelファイルに入っていて、それがどこに保存されているのかを覚えておかないと、いちいちファイルを開いて探さないといけないことです。

Rだとソースコードを残すことができますので、
どこにあるファイルを読み込んで、そこに何が入っているのかをコメントで残しておくことができます。

## 読み込んだデータの確認

MS Excelは読み込んだデータが画面上に表として表示されていますが、Rでは変数に代入しただけでは、画面には何も表示されません。
そこでデータの中身を確認する関数として、次のようなものがあります。

- `head()` : 最初の数行を表示させる基本関数
- `str()` : データの構造を表示させる基本関数
- `glimpse()` : データの構造を表示させるdplyrパッケージの関数
- `names()` : 変数名を表示させる基本関数

これらを使って、データの中身を確認し、データの形に適した処理方法を学ぶ必要があります。
以下では、`head()`関数を使って、データの最初の数行を表示させてから、`str()`関数でデータの中の変数とその型を確認します。

Excelは目視が中心ですが、見ただけでは、文字列なのか数なのかが分からないので、やはりデータの型は確認する必要があります。

:::{.callout-important}
## Rの場合
```{r}
head(df)
str(df)
```
:::

::: {.callout-tip}
## MS Excelの場合

画面を見て確認する。

:::

このデータには，

- `code` : 企業コード (文字列)
- `name` : 企業名 (文字列)
- `term` : 決算年月 (文字列)
- `shubetsu` : 会計基準の種類 (数値)
- `ren` : 連結か単体 (数値)
- `sales` : 売上高 (数値)
- `netincome` : 当期純利益 (数値)
- `month` : 決算月数 (数値)

が入っています。

## データの整形

### データ操作の基礎

さあ面白くなってきました。
次はデータを操作していきます。
Rによるデータ操作では、`tidyverse`パッケージ群の`dplyr`パッケージが大活躍します。

`dplyr`パッケージの関数の中でもよく使うものに次のようなものがあります。

- `select()` : 変数を選択する
- `filter()` : データを抽出する
- `mutate()` : 変数を追加する
- `arrange()` : データを並び替える
- `summarise()` : データを集計する
- `group_by()` : データをグループ化する

### パイプ演算子

Rでソースコードを書く際に，理解しやすく，読みやすいコードにするために非常に便利なのが，パイプ演算子`%>%`です。
パイプ演算子`%>%`は，左側のオブジェクトを右側の関数の第一引数に渡すという処理を行います。
たとえば，

```{r}
(1 + 2) %>% sqrt()
```
と書くと，`sqrt(1 + 2)`と同じ意味になります。
たとえば，`rnorm()`関数を使って平均0，分散1の標準正規分から100個のデータを作りたいとします。
`rnorm()`関数は3つの引数を取ります。

1. データの個数
2. 平均
3. 標準偏差

したがって，`rnorm(100, 0, 1)`と書くと，平均0，分散1の標準正規分布から100個のデータを取り出すことができます。
パイプ演算子を使うと，

```{r}
100 %>% rnorm(mean = 0, sd = 1)
```
となります。
これは`rnorm()`関数の第1引数がデータの個数なので，そこに`100`を渡しています。
ここで平均に値を渡したい場合を考えます。
`mean`引数は第2引数なので，パイプ演算子では自動で渡してくれません。
そこで`.`を使って渡す場所を指定してあげます。
```{r}
100 %>% rnorm(100, mean =. , sd = 1)
```
これで平均100，標準偏差1の正規分布から100個のデータを取り出せました。


これだけだとパイプ演算子`%>%`の便利さが伝わらないので，たとえば次のような処理を考えてみましょう。

1. 2020年のデータを抜き出し，
2. 売上高当期純利益率を計算し，
3. 産業グループごとに平均を計算する
4. 利益率が高い順番に並び替える

をパイプ演算子を使って書くと，

```{r}
#| eval: false
df <- df %>%
    filter(term == "2020") %>% # 2020年のみ
    mutate( # 新しい変数を作成
        ratio = netincome / sales # 売上高利益率
        ) %>%
    group_by(sangyo) %>% # 産業グループごとに
    summarise( # 平均を計算
        mean_ratio = mean(ratio) # 利益率の平均
        ) %>%
    arrange(desc(mean_ratio)) # 利益率の高い順に並び替え
```
のように，上から順番に処理を実行し，次に渡す，というプロセスが分かりやすく，読みやすいコードができました。
コメントも残しておけば，後から見返したときにも分かりやすいですし，他人によんでもらうときも親切ですね。
したがって，以下ではパイプ演算子を駆使して，データ操作を行っていきます。


### 新しい変数を作成する `mutate` {.unnumbered}

新しい変数を作成するには，`dplyr`パッケージの`mutate()`関数を使います。
先ほど読みこんだデータから，当期純利益を売上高で除して売上高当期純利益率を計算して，`ratio`という変数を作ってみましょう。

:::{.callout-important}
## Rの場合
```{r}
df <- df %>%
    mutate( # 新しい変数を作成
        ratio = netincome / sales # 売上高利益率
        )
```
:::

::: {.callout-tip}
## MS Excelの場合

`I1`のセルに変数名を表す`ratio`と入力する。
F列の`sale`とG列の`netincome`を使って，`I2`のセルに

`= G2 / F2`

とし，`I2`セルの右下の四角をダブルクリックすると，自動で下のセルにも同じ計算がコピーされる。
:::

次に，ある変数の値に応じて異なる値をとる変数を作るには，`mutate()`関数と`ifelse()`関数を同時に使います。`ifelse()`関数は次のような引数を取ります。

```{r}
#| eval: false
ifelse(条件, 条件が真のときの値, 条件が偽のときの値)
```

先ほど計算した売上高当期純利益率が5%以上ならば「高い」，そうでなければ「低い」という変数`highlow`を作ってみましょう。

:::{.callout-important}
## Rの場合
```{r}
df <- df %>%
    mutate( # 新しい変数を作成
        highlow = ifelse(ratio >= 0.05, "高い", "低い") # 売上高利益率
        )
```
:::

::: {.callout-tip}
## MS Excelの場合
`J1`セルに`highlow`と入力する。
`J2`セルに

` = if(I2 >= 0.05, "高い", "低い")`

と入力し，`J2`セルの右下の四角をダブルクリックすると，自動で下のセルにも同じ計算がコピーされる。
:::

Excelだとセルの移動や変数名の入力，計算式の入力，セルのコピーといった作業で，キーボードとマウスを行ったり来たりする必要があり，若干面倒です。

ついでに，`mutate()`関数を使って，長すぎる企業名を短くしてみます。
ここでは「ポーラ・オルビスホールディングス」を「ポーラ」と略してみます。
`mutate()`と`ifelse`を使って，`name`変数の値が「ポーラ・オルビスホールディング」ならば「ポーラ」という値をとる変数`name`上書きします。を作ってみましょう。

:::{.callout-important}
## Rの場合
```{r}
df <- df %>%
    mutate( # 新しい変数を作成
        name = ifelse(
            name == "ポーラ・オルビスホールディング", "ポーラ", name) # 企業名
        )
```
:::


### データを抽出する `filter` {.unnumbered}

データを抽出するには，`dplyr`パッケージの`filter()`関数を使います。
`filter()`関数は，次のような引数を取ります。

```{r}
#| eval: false
filter(データ, 条件)
```

先ほど作成した`ratio2`が「高い」企業だけを抽出してみましょう。
`filter()`関数の中の条件は，`==`を使って，`"高い"`という文字列と一致するかどうかを確認しています。
ここでは，`highlow`変数の値が`"高い"`と一致する企業だけを抽出し，`df_high`という変数に代入しています。

:::{.callout-important}
## Rの場合
```{r}
df_high <- df %>%
    filter(highlow == "高い") # 条件
```
:::

::: {.callout-tip}
## MS Excelの場合
highlow変数のあるJ列をクリックして枠を移動させ，上の「ホーム」メニューから「並び替えとフィルター」をクリックし，「フィルター」をクリックする。
すると，変数名highlowのヨコに漏斗のようなマークが出るので，それをクリックすると，記録されたデータの種類が出てくるので，「高い」だけにチェックが入った状態にする。
:::

Excelのクリック回数が増えてきましたね。

`filter()`関数の中で指定する条件は，

- `==` : 一致する
- `!=` : 一致しない
- `>=`や`<=` : 以上や以下
- `>`や`<` : より大きいや小さい
- `%in%` : いずれかに一致する

などがあります。またこれらの条件を組み合わせることもできます。
その場合は，以下のように`&`や`|`を使います。

- `&` : かつ
- `|` : または

たとえば，資生堂と花王を抽出したり，売上高当期純利益率が5%以上かつ売上高が1000億円以上の企業を抽出するには，
次のように書きます。

:::{.callout-important}
## Rの場合
```{r}
df_shiseido_kao <- df %>%
    filter(name %in% c("資生堂", "花王")) # 2社だけ抽出
df_high2 <- df %>%
    filter(ratio >= 0.05 & sales >= 1000) # 2条件を同時に満たす
```
:::



### 変数を選択する `select` {.unnumbered}

データの中から必要な変数だけを選択するには，`dplyr`パッケージの`select()`関数を使います。
たとえば，先ほど作成した`df`から，企業コード，企業名，売上高当期純利益率の3つの変数だけを選択してみましょう。

:::{.callout-important}
## Rの場合
```{r}
df3 <- df %>%
    select(code, name, ratio) # 3つの変数だけ選択
```
:::

::: {.callout-tip}
## MS Excelの場合
オリジナルのデータをコピーして，下のタブから別のシートを選択し，そこに貼り付ける。

貼り付けたデータから`code`と`name`と`ratio`以外の列を削除する。
:::

MS Excelだと，不要なデータを削除するのが怖い作業で，必要になったときにまた元のデータを読み込まないといけないので，面倒ですし，ミスのもとです。

`select()`関数の中で使えるものには，以下のようなものがあります。
とても便利なので，覚えておくとよいでしょう。

- `-` : 除外する (`-ratio`とかくと`ratio`以外を選択)
- `:` : 連続する変数を選択 (`code:ren`と書くと`code`から`ren`までを選択)
- `starts_with()` : ある文字列で始まる変数を選択
- `ends_with()` : ある文字列で終わる変数を選択

たとえば，`mutate()`で新しい変数を作る場合に，変数名に法則性をつけておけば，`starts_with()`を使って一気に変数を選択することができます。
たとえば，比率を表す変数は`ratio`で始まるように統一しておく，基準化した変数には`_K`を最後に付けておく，などです。

### データを並び替える `arrange` {.unnumbered}

データを並び替えるには，`dplyr`パッケージの`arrange()`関数を使います。
たとえば，先ほど作成した`df`から，売上高当期純利益率を並び替えてみましょう。

:::{.callout-important}
## Rの場合
```{r}
df %>%
    select(name, ratio) %>% # 2つの変数だけ選択
    arrange(ratio) %>%
    head()
```
:::
小さい順に並び替えられました。
大きい順にするには，`desc()`関数を使います。
ついでに`knitr`パッケージの`kabble()`関数で表を見やすく加工してみます。

:::{.callout-important}
## Rの場合
```{r}
df %>%
    select(name, ratio) %>% # 2つの変数だけ選択
    arrange(desc(ratio)) %>%
    head(10) %>% # 先頭の10行
    knitr::kable(booktabs = TRUE) # 表をきれいに表示
```
:::
これでどの企業のどの年度の売上高当期純利益率が大きいのかが一目瞭然になりました。

MS Excelだと，

::: {.callout-tip}
## MS Excelの場合

「ホーム」メニューから「並び替えとフィルター」をクリックし，「昇順」をクリックする。

必要なデータだけ選択してコピペすれば，表が完成します。
:::

となります。
簡単ですが，MS Excelの並び替えは注意が必要で，並び替えた後にデータを追加すると，並び替えが解除されてしまい，元に戻せなくなったり，空列があると並び替えがうまくいかなかったりします。


### long形式とwide形式

人間には読みやすいけれどパソコンは読みにくい，というデータの形式があります。
例えば下の表を見てみましょう。

| 地点 |   6時    |   12時   |   18時   |
|:----:|:--------:|:--------:|:--------:|
| 札幌 | 12℃  | 15℃  | 13℃  |
| 大阪 | 20℃  |  24℃  |  22℃  |
| 福岡 |  23℃  | 25℃  | 25℃  |

このような形のデータをワイド形式(wide)といいます。
天気予報で見かけそうなこの表は，人間にとっては分かりやすいですが，実はコンピュータにとっては，分かりにくいものです。
コンピュータが理解しやすいデータとして表すなら，次のような表になります。

| 地点 | 時間 |  気温(℃) |
|:----:|:----:|:-------:|
| 札幌 | 6時  |   12    |
| 札幌 | 12時 |   15    |
| 札幌 | 18時 |   13    |
| 大阪 | 6時  |   20    |
| 大阪 | 12時 |    24    |
| 大阪 | 18時 |    22    |
| 福岡 | 6時  |    23    |
| 福岡 | 12時 |   25    |
| 福岡 | 18時 |   25    |

このような形式のデータをロング型(long)といいます。
このロング型のうち，一定のルールに従って作成されたデータを**整然データ(tidy data)**といい，Rでは，この整然データを扱うことが多いです。

R神Hadley Wickham氏は，データの型を理解することを，データ分析の第一歩とし，その一貫として整然データという考え方を提唱しています。 整然データとは，次のような原則に従って構築されたデータのことです(Wickham, 2014) 参考[https://id.fnshr.info/2017/01/09/tidy-data-intro/](https://id.fnshr.info/2017/01/09/tidy-data-intro/)。

1.  個々の変数 (variable) が1つの列 (column) をなす。
2.  個々の観測 (observation) が1つの行 (row) をなす。
3.  個々の観測の構成単位の類型 (type of observational unit) が1つの表 (table) をなす。
4.  個々の値 (value) が1つのセル (cell) をなす

上の表は，地点，時間，天気，気温の4つの変数があり1つの列をつくっています(ルール1)。 大阪12時の天気は雨，気温は12℃といったように1つの行が1つの観測を表しています(ルール2)。 このデータには種類の異なる観測はない(ルール3)。 また，各セルには1つの値が入っています(ルール4)。 よって，これが整然データとなります。

上のロング型の天気データを使って，ロングからワイド，ワイドからロングの操作を学びましょう。

まずデータを作ります。
```{r}
df_weather <- data.frame(
    place = c("札幌","札幌","札幌","大阪","大阪","大阪","福岡","福岡","福岡"), # 各地を3個ずつ
    time = rep(c("6時", "12時", "18時"),3),
    temp = c(12,15,13,20,24,22,23,25,25)
)
print(df_weather)
```

これはロング型の整然データとなります。

### ロングからワイド `pivot_wider` {.unnumbered}

Rで使うならこのままでよいのですが，あえてこれをワイド型に変えてみましょう。

教科書で使用されている`spread()`は「根本的に設計ミスってた」と公式で発表されているので，R神が作った`pivot_wider()`を使います。widerという名前の通り，ワイド型に変換する関数です。

`pivot_wider()`の引数は，`names_from`と`values_from`です。`names_from`は，ワイド型に変換するときに，どの変数を列にするかを指定します。`values_from`は，ワイド型に変換するときに，どの変数の値を使うかを指定します。

以下のコードでは，`time`変数の値を列に，`temp`変数の値を値にして，`df_wide`という変数に代入しています。

```{r}
df_wide <- df_weather %>%
    pivot_wider(names_from = time, values_from = temp)
print(df_wide)
```

これでワイド型に変換できました。

### ワイドからロング `pivot_longer` {.unnumbered}


次に，このワイド型のデータをロング型に変換してみます。
教科書では，`tidyr`の`gather()`を使っていますが，これも`wider()`と同じ問題を持っているので，R神による`pivot_longer()`を使います。

`pivot_longer()`の引数は，`cols`と`names_to`と`values_to`です。

- `cols`は，ロング型に変換するときに，どの変数を行にするかを指定
- `names_to`は，ロング型に変換するときに，どの変数の値を使うかを指定
- `values_to`は，ロング型に変換するときに，どの変数の値を使うかを指定

以下のコードでは，`6時`，`12時`，`18時`の3つの変数を行に，`time`という変数の値を列に，`temp`という変数の値を値にして，`df_long`という変数に代入しています。

```{r}
df_long <- df_wide %>%
    pivot_longer(
        cols = c("6時", "12時", "18時"), # 縦にする変数
        names_to = "time", # 縦にした変数名
        values_to = "temp") # 値
print(df_long)
```

元のロング型に戻りました。

### データの結合

別々のデータを結合させて使いたいことはよくあります。
例えば，次のようなデータを結合させる場合を考えてみましょう。

#### 表A {.unnumbered}

| name | term | sale |
|:----|----:|----:|
|トヨタ | 2020 | 1000 |
|トヨタ | 2021 | 900 |
|トヨタ | 2022 | 1400 |
|ホンダ | 2020 | 800 |
|ホンダ | 2021 | 700 |
|ホンダ | 2022 | 900 |

```{r}
df_A <- data.frame(
    name = c("トヨタ", "トヨタ", "トヨタ", "ホンダ", "ホンダ", "ホンダ"),
    term = c(2020, 2021, 2022, 2020, 2021, 2022),
    sale = c(1000, 900, 1400, 800, 700, 900)
)
```

#### 表B {.unnumbered}

| name | term | sale |
|:----|----:|----:|
|日産 | 2020 | 400 |
|日産 | 2021 | 500 |
|日産 | 2022 | 900 |
|マツダ | 2020 | 300 |
|マツダ | 2021 | 400 |
|マツダ | 2022 | 200 |

```{r}
df_B <- data.frame(
    name = c("日産", "日産", "日産", "マツダ", "マツダ", "マツダ"),
    term = c(2020, 2021, 2022, 2020, 2021, 2022),
    sale = c(400, 500, 900, 300, 400, 200)
)
```

#### 表C {.unnumbered}

| name | term | netincome |
|:----|----:|----:|
|トヨタ | 2020 | 100 |
|トヨタ | 2021 | 90 |
|トヨタ | 2022 | 150 |
|ホンダ | 2020 | 140 |
|ホンダ | 2021 | 100 |
|ホンダ | 2022 | 90 |
|スバル | 2020 | 30 |
|スバル | 2021 | 35 |
|スバル | 2022 | 50 |

```{r}
df_C <- data.frame(
    name = c("トヨタ", "トヨタ", "トヨタ", "ホンダ", "ホンダ", "ホンダ", "スバル", "スバル", "スバル"),
    term = c(2020, 2021, 2022, 2020, 2021, 2022, 2020, 2021, 2022),
    netincome = c(100, 90, 150, 140, 100, 90, 30, 35, 50)
)
```


この3つのデータを結合させる場合を考えます。
まず表Aと表Bは同じ変数をもつデータなので，これらを結合させるには，縦につなげる必要があります。
このような結合を**縦結合**とか連結といいます。
縦結合は，`dplyr`パッケージの`bind_rows()`関数を使います。


```{r}
df_AB <- bind_rows(df_A, df_B)
print(df_AB)
```
縦に結合できたので，トヨタ，ホンダ，日産，マツダのデータが入ったデータベース`df_AB`ができました。

次に，この`df_AB`と`df_C`を結合させます。
`df_C`は`netincome`という`df_AB`にはない変数があり，異なる変数をもつデータ同士の結合となります。
これらを結合させるには，横につなげる必要があります。
このような結合を**結合**といいます。

結合には，

- **内部結合**(inner join)
- **外部結合**(outer join)

があり，外部結合には，

- **完全結合**(full join)
- **左結合**(left join)
- **右結合**(right join)

があります。

内部結合は**両方のデータベースに存在する観測値のみを保持**するため，多くのデータが欠落することになりますが，**外部結合**は、少なくとも1つのテーブルに存在する観測値を保持するので，大部分のデータが欠落することにはなりません。

3つの外部結合の特徴は次の通りです。

- **完全結合**は、xとyのすべての観測値を保持します。
- **左結合**は、xのすべての観測値を保持します。
- **右結合**は、yのすべての観測値を保持します。

R神の神書籍[R for Data Science (2e)](https://r4ds.hadley.nz/)の図がわかりやすいので，ここで紹介します。

![外部結合の例](img/R4D_join.png)

内部結合と3つの外部結合をベン図で表すとこうなります。

![外部結合のベン図](img/R4D_outer_join.png)

最もよく使われる結合は**左結合**です。
元データに他のデータを結合する場合，元データに含まれるデータのみ保持したい場合が多いので，追加データを調べるときはいつもこれを使います。
左結合はデフォルトの結合であるべきで、他の結合を選択する強い理由がない限り、これを使用します。

では，`df_AB`と`df_C`を左結合してみましょう。
結合する際にキーとなる変数を指定する必要があります。
ここでは`name`と`term`の2つの変数をキーとして指定します。
こうすることで，`name`と`term`が一致する観測値を結合します。

```{r}
df_left <- df_AB %>%
    left_join(df_C, by = c("name", "term"))
print(df_left)
```

`df_AB`にはトヨタ，ホンダ，日産，マツダのデータがありますが，`df_C`には日産とマツダのデータがなく，スバルのデータがあります。
そのため左結合すると，日産とマツダの`netincome`には`NA`が入り，スバルは欠落します。


`df_AB`と`df_C`を右結合してみましょう。

```{r}
df_right <- df_AB %>%
    right_join(df_C, by = c("name", "term"))
print(df_right)
```

`df_C`には日産とマツダのデータがなく，トヨタとホンダとスバルのデータがあります。
そのため右結合すると日産とマツダのデータが欠落し，`df_C`に含まれていたトヨタ，ホンダ，スバルのデータが残ります。
しかしスバルの`sale`には`NA`が入ります。

最後に，`df_AB`と`df_C`を完全結合してみましょう。

```{r}
df_full <- df_AB %>%
    full_join(df_C, by = c("name", "term"))
print(df_full)
```

`df_AB`にはトヨタ，ホンダ，日産，マツダのデータがありますが，`df_C`にはトヨタ，ホンダ，スバルのデータがあるため，
完全結合した`df_full`にはすべての企業のデータが入ります。
しかし，日産とマツダの`netincome`には`NA`が入り，スバルの`sale`にも`NA`が入ります。

このように，結合するデータによって，結合したデータに含まれるデータが変わるので，自分が望む結合後のデータの形を考えて，どの結合を使うかを選ぶ必要があります。

ついでに内部結合もやってみましょう。


```{r}
df_inner <- df_AB %>%
    inner_join(df_C, by = c("name", "term"))
print(df_inner)
```

予想どおり，両方のデータに含まれているトヨタとホンダだけが残り，片方のデータにしか含まれていない日産，マツダ，スバルのデータは欠落してしまいました。
このように内部結合は，両方のデータに存在する観測値のみを保持するため，多くのデータが欠落することになり，利用する機会があまりないです。


## データの保存

前処理が終わったデータは，ファイルとして保存しておくとよいでしょう。
たとえば，`df_left`を`df_left.csv`というファイル名で保存するには，`readr`パッケージの`write_csv()`関数を使います。

`write_csv()`関数の第1引数は保存したいオブジェクト(ここでは`df_left`)で，あとの主要な引数は，

- `file`
- `na = "NA"`
- `append = FALSE`

となります。
`file`は保存するファイル名を指定します。
`na`は欠損値をどうするかを指定します。デフォルトでは`NA`となっています。
`append`は，既存のファイルに追記するかどうかを指定します。基本は上書きなので，`FALSE`にしておきます。

```{r}
write_csv(df_left, file = "df_left.csv")
```

これで，作業ディレクトリに`df_left.csv`が保存されました。
分析を進める際は，このようにして保存したデータを読み込んで使います。

